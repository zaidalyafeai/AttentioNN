{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerII.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaidalyafeai/AttentioNN/blob/master/TransformerII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y8_IQ8ybFW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget http://data.mxnet.io/data/fra-eng.zip\n",
        "!unzip fra-eng.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOpL_MbL0Fog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('fra.txt', 'r') as f:\n",
        "  sentences = f.read().splitlines()\n",
        "  en = [sentence.split('\\t')[0] for sentence in sentences]\n",
        "  fr = [sentence.split('\\t')[0] for sentence in sentences]\n",
        "\n",
        "with open('en.txt', 'w') as f:\n",
        "  f.write(('\\n'.join(en)))\n",
        "\n",
        "with open('fr.txt', 'w') as f:\n",
        "  f.write(('\\n'.join(fr)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9VSOO9fh_Iz",
        "colab_type": "code",
        "outputId": "0f874a30-cdfb-4c3c-f35e-290f6cece3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaxuWASijLzE",
        "colab_type": "text"
      },
      "source": [
        "## Introduction \n",
        "\n",
        "Until 2017, natural language processing (NLP) was dependent on using recurrent neural networks (RNNs) which has many shortcomings: 1. no support for parallelization, 2. vanishing gradient for long sequences. For instance, in translation which is mostly seq2seq architectures, both the encoder and decoder consists of RNNs. In 2014, Bahdanau et al , suggested the use of a mechanism called \"attention\" to resolve the bottleneck of seq2seq models [1]. However, RNNs were still the main building blocks for such models and others like image captioning by Kelvin Xu et al [2]. The use of attention in [1, 2] gave a better visualization of such models. But, what if we get rid of all RNNs in the first place. Well, that is a big claim, but it worked really well in 2017. The paper was rightly called \"Attention is all you need\" by Vaswani et al. from Google AI. This is a breakthrough, since RNNs are very slow which makes parallel computations easy to implement. The model was called 'Transfomer model', in this notebook we will explain in details its main components. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkUl87Y5h2bl",
        "colab_type": "text"
      },
      "source": [
        "## Transformer Decoder\n",
        "\n",
        "The transofmer, like other architectures for machine translation consists of encoder and decoder modules. In this notebook, we will only focus on the decoder, check the first part that discusses the [encoder](https://colab.research.google.com/github/zaidalyafeai/AttentioNN/blob/master/TransformerI.ipynb).\n",
        "\n",
        "![alt text](https://miro.medium.com/max/2880/1*BHzGVskWGS_3jEcYYi6miQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmrbrXgsYEYH",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "Given a set of statements we would like to convert these statements to a set of integers. However, this will result in a huge vocabulary which makes training very difficult. Google offers [SentencePiece](https://github.com/google/sentencepiece) which is a model that could be trained to generate tokens for arbitrary languages. From the name, you could deduce that the model can generate pieces of words as well. In this example, we will train a model on a set of expressions from the English language. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UVgskFrbMaO",
        "colab_type": "code",
        "outputId": "430cf61b-2402-4b9c-89eb-f04e6beb68a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train the model on the epxressions with a fixed vocabulary size, this will create a model named en.model \n",
        "spm.SentencePieceTrainer.Train('--input=en.txt --model_prefix=en --vocab_size=10000')\n",
        "\n",
        "# create the process object then load the trained model\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('en.model')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2pbXnG7pwhQ",
        "colab_type": "text"
      },
      "source": [
        "Now, let us load our dataset and convert them to padded vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iac8SK5bbuI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the expressions \n",
        "with open('en.txt', 'r') as f:\n",
        "  sentences = f.read().splitlines()\n",
        "\n",
        "# convert the vectors to ids \n",
        "sequences = []\n",
        "max_length = 0\n",
        "\n",
        "for sentence in sentences[0:1000]:\n",
        "  sequence = sp.encode_as_ids(sentence)\n",
        "  sequences.append(sequence)\n",
        "  max_length = max(max_length, len(sequence))\n",
        "\n",
        "# pad the vectors according to the longest sequence \n",
        "x = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen = max_length, padding = 'post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JjjtCUqe9Zh",
        "colab_type": "text"
      },
      "source": [
        "## Parameters\n",
        "A set of parameters that are taken from the original paper. Don't worry about them right now. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiSSscLYoxbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimension of the vectors between consecutive modules layers \n",
        "dm = 512\n",
        "\n",
        "# number of heads in attention modules\n",
        "h = 8 \n",
        "\n",
        "# dimensnion of queries and keys \n",
        "dk = dm // 8\n",
        "\n",
        "# dimension of values \n",
        "dv = dm // 8 \n",
        "\n",
        "# sequence length \n",
        "n = max_length \n",
        "\n",
        "# size of vocabulary \n",
        "vocab_size = 10000\n",
        "\n",
        "# number of neurons in the feed forward network \n",
        "dff = 2048"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSVKuZZfXz3H",
        "colab_type": "text"
      },
      "source": [
        "## Encoding\n",
        "Since the transformer model has no meaning of sequences of operations (they are mostly parallel) for a set of words, it is important that we keep track of the order input words. To do that, we use positional encoding. Before doing that, we will first pass the vectors through an embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDFnZhaUgiC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = tf.keras.layers.Embedding(vocab_size, dm)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZhKNkIhrH1C",
        "colab_type": "text"
      },
      "source": [
        "To encode the position of each word within a sequence of models we use sines and cosines. These encodings are just added to the embedding layer output so no change in the shape of e: [None, dm]. \n",
        "\n",
        "Given pos as the position within the sequence which takes the values $0 \\cdots n-1$ and $i$ as the position within the embedding dimension which takes values $0 \\cdots d_m-1$. We evaluate the encoded position for even and odd values as "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-mcPNbN1KsS",
        "colab_type": "text"
      },
      "source": [
        "$$\\text{PE}(\\text{pos},2i)= \\sin\\left(\\frac{\\text{pos}}{10000^{2i/d_{model}}}\\right)$$\n",
        "\n",
        "$$\\text{PE}(\\text{pos},2i+1)= \\cos\\left(\\frac{\\text{pos}}{10000^{2i/d_{model}}}\\right)$$\n",
        "\n",
        "We can combine the two formulas as \n",
        "\n",
        "$$\\text{PE}(\\text{pos},i)= \\sin\\left(\\frac{\\text{pos}}{10000^{(i-g(i))/d_{model}}}+ g(i) \\times \\frac{\\pi}{2}\\right)$$\n",
        "\n",
        "Where $g(i) = i \\,\\% \\,2$ which takes 0 for even values and 1 for odd values. Note that $\\sin(x + \\pi/2) = \\cos(x)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogeEJ19D1Hql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g(ids):\n",
        "  return ids % 2\n",
        "\n",
        "def positional_encoding(x):\n",
        "\n",
        "  # 1. create positions within sequence and ids within dm \n",
        "  # out ids: [1, dm] pos: [n, 1]\n",
        "  ids = tf.expand_dims(tf.range(0, dm), 0)\n",
        "  pos = tf.expand_dims(tf.range(0, n), 1)\n",
        "\n",
        "  # 2. create numerator and denominator\n",
        "  # inp ids: [1, dm] pos: [n, 1] \n",
        "  # out den: [1, dm] num: [n, 1]\n",
        "  den = tf.pow(10000.0, tf.cast((ids - g(ids))/ dm, tf.float32))\n",
        "  num = tf.cast(pos, tf.float32)\n",
        "\n",
        "  # 3. division ahmed show\n",
        "  # inp num: [n, 1] den: [1, dm] \n",
        "  # out encoding: [n, dm]\n",
        "  encoding = tf.sin(tf.divide(num, den)  + tf.cast(g(ids), tf.float32)* (np.pi/2))\n",
        "  return x + encoding\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-RkWoOeffxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = positional_encoding(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3RE5xk3veFD",
        "colab_type": "text"
      },
      "source": [
        "Let us visualize the encoding for a specific sequence of words. As we see from the figure there is a unique pattern for the sequence position in the y-axis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "socxYh9DXeLV",
        "colab_type": "code",
        "outputId": "6d927858-ee6d-4d41-8fe7-5ae6eab30f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "plt.figure(figsize = (10, 5))\n",
        "plt.pcolormesh(z[0])\n",
        "plt.ylim((0, max_length))\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAEzCAYAAAD0NpN+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npqxue4Ogyc_",
        "colab_type": "text"
      },
      "source": [
        "## Masked Multi-head Self-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qRm-ll7VxLR",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/img/MultiHead.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRqD7sWxXfsj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let us start by the output of the positional encoding function $z \\in \\mathbb{R}^{n \\times d_m}$. Note that, for simplicity we assume that we just have one batch. From the value $z$ we extract three types of vectors by applying three dense layers. The types are $K \\in \\mathbb{R}^{n \\times d_k} Q \\in \\mathbb{R}^{n \\times d_k}$ and $V \\in \\mathbb{R}^{n \\times d_v}$ called keys, queries and values respectively. In simple terms, the keys are used by the query vector to search for values. In attention, we are trying to find the closest key-value pair to the given query vector. In other words, we are trying to search for words that are closer in meaning or may refer to in the current context. For instance, in the statement `John is smart and handsome` we expect that the query words `smart` and `handsome` to have an high attention value for the key word `John`. To evaluate closensess, we a scaled dot product \n",
        "\n",
        "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
        "\n",
        "This function will result in a weight vector for each query word multiplied by the value vector. For instance, for the query word `smart` we expect something like `[0.3, 0.05, 0.1, 0.05, 0.55] x v`. Hence, smaller values of the attention weight vector will result in smaller values and hence lower gradient. The authors, realized that for larger values the dot product might grow large so they divide by $\\sqrt{d_k}$ as a normalizing factor inside the softmax function. In general, this is called additive attention which is usually preferred because is fast and space efficient because we can use highly optimized matrices product to compute it. Note that, in the definition we assume that $Q, K, V$ are matrices hence it can be computed really fast for a large sequence and even batch size. There exists another form of attention, which is called product attention which was used in [1, 2]. \n",
        "\n",
        "In general this approach is called self-attention because it uses the same input vector $z$ to generate the queue, key and value vectors. In the paper, the authors suggest using self-attention multiple times i.e multiple head attention. This is done by repeating the same operation multiple times which in general gave more robust results. They use $h = 8$  and then concatenate the output at the end. In the decocer the authors applied masked self-attention where the current token is only able to attent to all tokens proceeding it in position. Hence, they cannot see future values. Let us take an example, consider the following matirx \n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "-1.37433722 &-0.53638396 & -0.36027966 \\\\\n",
        "-1.15409807 & -1.54633265 & 1.04451533 \\\\\n",
        " 1.25598085 & -0.52104727 & -1.08935325\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "We apply a simple trick by replacing upper traingle by - infinity values as a masking value\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "-1.37433722 &-\\infty & -\\infty \\\\\n",
        "-1.15409807 & -1.54633265 & -\\infty \\\\\n",
        " 1.25598085 & -0.52104727 & -1.08935325\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "By applying `softmax` function \n",
        "\n",
        "$$ \\begin{bmatrix}\n",
        "1.        & 0.    &     0. \\\\        \n",
        "0.5968205 & 0.40317947 & 0.  \\\\      \n",
        "0.79054177 & 0.13371228 & 0.07574591 \\\\\n",
        "\\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UVzDMR69VXv",
        "colab_type": "text"
      },
      "source": [
        "In the following function we will create a multi head attention operation. The input vector has dimensions $z \\in \\mathbb{R}^{\\text{None} \\times n \\times d_m}$ and the output $H \\in \\mathbb{R}^{\\text{None} \\times n \\times d_m}$ note how we use $\\text{None}$ to represent the batch size which could be of variable size. To make the code clearer, for each operation I show the input and output dimension shapes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R8HkG62tiaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mask previous tokens by replacing them with -inf th\n",
        "def mask(x):\n",
        "  # 1. scaled dot product \n",
        "  # inp x: [None, n, n]\n",
        "  # out y: [None, n, n] \n",
        "  mask = tf.linalg.band_part(tf.ones((n, n)), -1, 0)\n",
        "  y = x*mask+(mask-1)/mask\n",
        "  return y\n",
        "\n",
        "def h_linear(x, dout):\n",
        "  # inp x:[None, n, dm] \n",
        "  # out x:[None, h, n, dout] \n",
        "  x = tf.keras.layers.Dense(units = dm)(x)\n",
        "  x = tf.reshape(x, (-1, h, n, dout))\n",
        "  return x\n",
        "\n",
        "def multi_head_attention(Q, K, V, masked = False):\n",
        "\n",
        "  # 0. apply linear layers \n",
        "  # inp Q:[None, n, dm] K: [None, h, n, dm] V: [None, h, n, dm] \n",
        "  # out Q:[None, h, n, dk] K: [None, h, n, dk] V: [None, h, n, dv]   \n",
        "  Q = h_linear(Q, dk)\n",
        "  K = h_linear(K, dk)\n",
        "  V = h_linear(V, dv)\n",
        "\n",
        "  # 1. scaled dot product \n",
        "  # inp Q:  [None, h, n, dk] K: [None, h, n, dk] \n",
        "  # out score : [None, h, n, n] \n",
        "  score = tf.matmul(Q, K, transpose_b=True)/ tf.sqrt(dk*1.0)\n",
        "\n",
        "  # 3. evaluate the mask \n",
        "  # inp score: [None, h, n, n]\n",
        "  # out score: [None, h, n, n]\n",
        "  if masked:\n",
        "    score = mask(score)\n",
        "\n",
        "  # 3. evaluate the weights \n",
        "  # inp score: [None, h, n, n]\n",
        "  # out W: [None, h, n, n]\n",
        "  W = tf.nn.softmax(score, axis = -1)\n",
        "\n",
        "  # 4. evaluate the context vector \n",
        "  # inp W: [None, h, n, n] V: [None, h, n, dv]\n",
        "  # out H: [None, h, n, dv]\n",
        "  H = tf.matmul(W, V)\n",
        "\n",
        "  # 5. concatenate all heads\n",
        "  # inp H: [None, h, n, dv]\n",
        "  # out H: [None, n, dv*h]\n",
        "  H = tf.reshape(H, (-1, n, dv * h))\n",
        "\n",
        "  # 6. linear layer\n",
        "  # inp H: [None, h, n, dv]\n",
        "  # out H: [None, n, dm]\n",
        "  out = tf.keras.layers.Dense(units = dm)(H)\n",
        "  \n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FliBr-UZ-AOP",
        "colab_type": "text"
      },
      "source": [
        "Finally, the decoder layer will be ready by applying fully connected layers and normalizations. Note that the authors used residual connections $$\\text{LayerNorm}(x + \\text{Sublayer}(x))$$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Z4jQRLhD01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DecoderLayer(z, z_encoder):\n",
        "\n",
        "  # 1. masked multi-head attention\n",
        "  # inp z : [None, n, dm]\n",
        "  # out dz: [None, n, dm]\n",
        "  dz = multi_head_attention(z, z, z, masked = True)\n",
        "\n",
        "  # 2. normalization\n",
        "  # inp z: [None, n, dm] dz: [None, n, dm]\n",
        "  # out z: [None, n, dm]\n",
        "  z = tf.keras.layers.LayerNormalization()(z + dz)\n",
        "\n",
        "  # 3. unmasked multi-head attention\n",
        "  # inp z : [None, n, dm]\n",
        "  # out dz: [None, n, dm]\n",
        "  dz = multi_head_attention(z, z_encoder, z_encoder, masked = False)\n",
        "\n",
        "  # 5. normalization\n",
        "  # inp z: [None, n, dm] dz: [None, n, dm]\n",
        "  # out z: [None, n, dm]\n",
        "  z = tf.keras.layers.LayerNormalization()(z + dz)\n",
        "\n",
        "  # 6. feed forward \n",
        "  # inp z : [None, n, dm]\n",
        "  # out dz: [None, n, dm]\n",
        "  dz = tf.keras.layers.Dense(units = dff, activation = 'relu')(z)\n",
        "  dz = tf.keras.layers.Dense(units = dm)(dz)\n",
        "\n",
        "  # 7. normalization \n",
        "  # inp z: [None, n, dm] dz: [None, n, dm]\n",
        "  # out z: [None, n, dm]\n",
        "  z = tf.keras.layers.LayerNormalization()(z + dz)\n",
        "\n",
        "  return z "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVRZJd5WnR_Y",
        "colab_type": "code",
        "outputId": "11c04412-5dbd-4d65-da6f-2c395710ca67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "DecoderLayer(z, z).shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1000, 7, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ecSrhheaNAM",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "1. [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) \n",
        "2. [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\n",
        "](https://arxiv.org/abs/1502.03044)\n",
        "3.  [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
        "4. https://www.tensorflow.org/tutorials/text/transformer\n",
        "5. [The Illustrated GPT-2](http://jalammar.github.io/illustrated-gpt2/)"
      ]
    }
  ]
}